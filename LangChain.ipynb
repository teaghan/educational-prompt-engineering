{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2089342-d2ce-436f-b2da-d0d33aeab911",
   "metadata": {},
   "source": [
    "# LangChain: Creating an AI Tutor for Astronomy 12\n",
    "\n",
    "In this tutorial, we'll build an AI tutor chatbot tailored for an [Astronomy 12 course](https://teaghan.github.io/astronomy-12/). \n",
    "\n",
    "By integrating techniques like conversational retrieval-augmented generation (RAG) with course-specific content, we aim to provide a tool that enhances student learning through interactive and personalized tutoring sessions.\n",
    "\n",
    "> For a more interactive experience, check out the [web app](https://teaghan-educational-prompt-engineering-tutormain-dkogwm.streamlit.app/) version for this chatbot.\n",
    "\n",
    "### Objectives\n",
    "\n",
    "- **Load and Process Educational Material**: Retrieve course material and convert the raw text into structured data that the AI can understand.\n",
    "- **Embedding for Information Retrieval**: Use advanced NLP techniques to make the course content readily accessible to the AI.\n",
    "- **Conversation History Management**: Ensure the AI can remember and utilize past interactions to provide contextually relevant responses.\n",
    "- **Content Retrieval**: Develop a method for the AI to gather the most contextually relevant information from its knowedge to best address the question.\n",
    "- **Setup a Dynamic Question Answering System**: Allow the AI to answer questions intelligently and contextually.\n",
    "\n",
    "---\n",
    "\n",
    "## Setup and Configuration\n",
    "\n",
    "### Environment Preparation\n",
    "\n",
    "First, we'll import the necessary libraries and configure our environment, including setting up API keys for accessing Langchain and OpenAI services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b65deaa-927d-4bf1-9496-3cfb0f37a587",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.schema import Document\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain.chains import create_history_aware_retriever, create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b207b4d-0a5b-4c27-a647-ee13210974bd",
   "metadata": {},
   "source": [
    "### Secure API Key Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a8937c7-6e90-4c6f-8588-3bc193b28645",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_api_key(key_file):\n",
    "    with open(key_file) as f:\n",
    "        key = f.read().strip(\"\\n\")\n",
    "    return key\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = load_api_key('key.txt')\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = load_api_key(key_file='langchain_key.txt')\n",
    "os.environ['USER_AGENT'] = 'myagent'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65f020e-efd3-459c-9a9b-c5a631c87ee1",
   "metadata": {},
   "source": [
    "## Integrating Course Content\n",
    "\n",
    "### Loading Course Documents\n",
    "\n",
    "Here we load the textual content of the Astronomy 12 course. These documents form the backbone of our AI tutor's knowledge base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9613be68-a221-4b41-a382-e7a05cb50489",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_text_file(file_path):\n",
    "    return open(file_path, 'r').read()\n",
    "\n",
    "tutor_instructions = load_text_file('tutor/Tutor_Instructions.txt')\n",
    "course_content = load_text_file('tutor/course_content.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b0804f-5407-4f63-bf1b-fb929e8a091e",
   "metadata": {},
   "source": [
    "### Structuring the Content\n",
    "\n",
    "Breaking down the course material into structured documents allows the AI to navigate and retrieve specific information efficiently.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95c10183-cb4d-448f-b04b-7d165e6913bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_by_files(content, context_window):\n",
    "    # Define patterns for splitting based on README, lesson files, and assignments\n",
    "    readme_pattern = r\"# Unit\\d+_README\\.md\"\n",
    "    lesson_pattern = r\"# \\d+_\\d+_[\\w_]+\\.md\"\n",
    "    assignment_pattern = r\"# Unit \\d+ Assignment\"\n",
    "\n",
    "    # Combine all patterns\n",
    "    combined_pattern = f\"({readme_pattern}|{lesson_pattern}|{assignment_pattern})\"\n",
    "    \n",
    "    # Find all matches (file sections) and split the content\n",
    "    matches = re.split(combined_pattern, content)\n",
    "\n",
    "    # Collect file content\n",
    "    chunks = []\n",
    "    for i in range(1, len(matches), 2):\n",
    "        chunk_title = matches[i].strip()\n",
    "        chunk_content = matches[i + 1].strip()\n",
    "\n",
    "        # Check the length of the chunk_content and split if necessary\n",
    "        if chunk_content:\n",
    "            content_length = len(chunk_content)\n",
    "            if content_length <= context_window:\n",
    "                chunks.append(Document(page_content=chunk_content, metadata={\"title\": chunk_title}))\n",
    "            else:\n",
    "                # Split the content into smaller chunks if it exceeds the context window\n",
    "                part_number = 0\n",
    "                for start in range(0, content_length, context_window):\n",
    "                    end = start + context_window\n",
    "                    part_number += 1\n",
    "                    subtitle = f\"{chunk_title} ({part_number})\"\n",
    "                    # Ensure the split does not cut off mid-word\n",
    "                    if end < content_length and not chunk_content[end].isspace():\n",
    "                        # Find the nearest space to avoid splitting words\n",
    "                        end = chunk_content.rfind(' ', start, end)\n",
    "                    sub_content = chunk_content[start:end].strip()\n",
    "                    if sub_content:\n",
    "                        chunks.append(Document(page_content=sub_content, metadata={\"title\": subtitle}))\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81fc23f-9a0e-45f6-8921-2de9d968c835",
   "metadata": {},
   "source": [
    "## Building the Chatbot\n",
    "\n",
    "### Initializing AI Models for Embedding and Interaction\n",
    "\n",
    "To empower our AI tutor with the capability to understand and process natural language effectively, we initialize two key components from the OpenAI suite: the embedding model and the language model. \n",
    "\n",
    "- **`OpenAIEmbeddings`**: Converts textual content into numerical vectors, capturing semantic meanings essential for tasks like document retrieval and context understanding.\n",
    "\n",
    "- **`ChatOpenAI` with `model=\"gpt-4o-mini\"`**: This language model processes and generates human-like text, enabling the AI to provide coherent, contextually appropriate responses, balancing performance with resource efficiency for real-time interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0e46222-24cc-43a8-a8ad-f46d925b5f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"gpt-4o-mini\"\n",
    "embedding_model = OpenAIEmbeddings()\n",
    "llm = ChatOpenAI(model=model)\n",
    "\n",
    "# Determine max context window for model used\n",
    "model_context_windows = {\n",
    "    \"gpt-4o\": 128000,\n",
    "    \"gpt-4o-2024-05-13\": 128000,\n",
    "    \"gpt-4o-2024-08-06\": 128000,\n",
    "    \"chatgpt-4o-latest\": 128000,\n",
    "    \"gpt-4o-mini\": 128000,\n",
    "    \"gpt-4o-mini-2024-07-18\": 128000,\n",
    "    \"gpt-4-turbo\": 128000,\n",
    "    \"gpt-4-turbo-2024-04-09\": 128000,\n",
    "    \"gpt-4-turbo-preview\": 128000,\n",
    "    \"gpt-4-0125-preview\": 128000,\n",
    "    \"gpt-4-1106-preview\": 128000,\n",
    "    \"gpt-4\": 8192,\n",
    "    \"gpt-4-0613\": 8192,\n",
    "    \"gpt-4-0314\": 8192,\n",
    "    \"gpt-3.5-turbo-0125\": 16385,\n",
    "    \"gpt-3.5-turbo\": 16385,\n",
    "    \"gpt-3.5-turbo-1106\": 16385,\n",
    "    \"gpt-3.5-turbo-instruct\": 4096\n",
    "}\n",
    "context_window = model_context_windows[model]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbca81c-ad0e-4608-92f9-b28f640b34de",
   "metadata": {},
   "source": [
    "### Embedding Documents\n",
    "\n",
    "Document embedding is a crucial step in preparing our AI tutor for effective teaching. This process transforms the segmented course material—such as lessons and sections—into numerical vectors that the AI can understand and analyze, akin to how a student internalizes topics for easier recall.\n",
    "\n",
    "#### Importance of Chunks\n",
    "\n",
    "Segmenting the course content into smaller, manageable chunks serves three key purposes:\n",
    "\n",
    "1. **Improved Retrieval Accuracy**: By organizing the material into distinct topics, the AI can more precisely identify and fetch relevant information in response to student queries, enhancing the educational experience.\n",
    "   \n",
    "2. **Efficient Processing**: Smaller text chunks lead to more targeted embeddings, allowing for quicker and more accurate retrieval of information.\n",
    "\n",
    "3. **Focused Content Delivery**: This approach mimics a tutor's method of referencing specific textbook sections to answer questions, providing students with precise and relevant information.\n",
    "\n",
    "#### Embedding Process\n",
    "\n",
    "Here’s a brief overview of how embedding benefits the AI tutor:\n",
    "\n",
    "- **Vector Representation**: Each document chunk is converted into a vector that captures its semantic meaning, enabling the AI to understand content beyond mere keywords.\n",
    "\n",
    "- **Semantic Understanding**: These vectors help the AI grasp underlying concepts within the text, similar to a student understanding ideas for application rather than rote memorization.\n",
    "\n",
    "- **Efficient Query Matching**: When a query is made, the AI quickly identifies the most relevant document chunks, ensuring accurate and contextually appropriate responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41563596-be6b-414f-b941-a8e3dec033b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "course_content = split_by_files(course_content, context_window)\n",
    "tutor_instructions = Document(page_content=tutor_instructions, metadata={\"title\": \"Tutor Instructions\"})\n",
    "course_content_vecs = Chroma.from_documents(course_content, embedding=embedding_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819ef9bf-ddf8-41c3-a243-d35e72ad28be",
   "metadata": {},
   "source": [
    "### Managing Conversation History\n",
    "\n",
    "Effective tutoring requires remembering past interactions, and our AI tutor uses conversation history management to achieve this. By maintaining a record of each student's dialogue, the AI can provide responses that are not only accurate but also contextually relevant to ongoing discussions.\n",
    "\n",
    "#### Implementation Details\n",
    "\n",
    "We utilize a simple but effective method to store and retrieve conversation histories based on session identifiers.\n",
    "\n",
    "**Key Components:**\n",
    "- **`store`**: A dictionary that holds conversation histories keyed by session identifiers.\n",
    "- **`get_session_history`**: A function that retrieves an existing history or creates a new one if none exists for the given session ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f323e7a7-aab6-41d0-bb0b-4e1b47aed718",
   "metadata": {},
   "outputs": [],
   "source": [
    "store = {}\n",
    "def get_session_history(session_id: str):\n",
    "    return store.setdefault(session_id, ChatMessageHistory())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce9b590-d785-4c09-917d-1fba9525cac4",
   "metadata": {},
   "source": [
    "### Setting Up the Chatbot Interaction\n",
    "\n",
    "To effectively tutor students, our AI chatbot uses a sophisticated interaction system that leverages both the context of the conversation and the knowledge embedded in the documents. This setup ensures that the responses are not only precise but also tailored to the specific educational needs of the student.\n",
    "\n",
    "#### Implementing Context-Aware Question Handling\n",
    "\n",
    "The AI tutor is designed to process inquiries by considering the entire conversation history, ensuring that each response builds on previous interactions.\n",
    "\n",
    "**Key Components:**\n",
    "- **`contextualize_q_system_prompt`**: A prompt that instructs the AI to reformulate the student's query into a clear, standalone question. This helps in stripping any ambiguity that might arise from a lack of context, making sure the question is clear and precise.\n",
    "- **`contextualize_q_prompt`**: This template structures the reformulation process, integrating the system's instructions with the user's input and the chat history.\n",
    "- **`history_aware_retriever`**: It leverages the reformulated question to fetch the most relevant information from the embedded documents. This retriever is aware of the chat history, which allows it to consider previous exchanges when selecting content to use in responses.\n",
    "\n",
    "By refining questions based on the chat history and directly retrieving information from contextually embedded documents, the AI tutor mimics a knowledgeable and attentive human tutor. This method ensures that each interaction is informed by a comprehensive understanding of both the course content and the student's ongoing educational journey."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6155af67-95b9-4bbd-aa28-8c100202d762",
   "metadata": {},
   "outputs": [],
   "source": [
    "contextualize_q_system_prompt = (\n",
    "    \"Given a chat history and the latest user question \"\n",
    "    \"which might reference context in the chat history, \"\n",
    "    \"formulate a standalone question which can be understood \"\n",
    "    \"without the chat history. Do NOT answer the question, \"\n",
    "    \"just reformulate it if needed and otherwise return it as is.\"\n",
    ")\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", contextualize_q_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "])\n",
    "\n",
    "history_aware_retriever = create_history_aware_retriever(llm, course_content_vecs.as_retriever(), contextualize_q_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8fa555-279a-4582-8e36-a4e4665b8a4a",
   "metadata": {},
   "source": [
    "### Integrating Document-Based Responses\n",
    "\n",
    "For our AI tutor to function as an effective educational tool, it's crucial to integrate the tutor's guidance directly into the system's responses. This integration ensures that the tutor not only answers queries but does so in a manner that aligns with the educational objectives and instructions specified in the tutor guidelines.\n",
    "\n",
    "#### Creating a Contextual Response System\n",
    "\n",
    "We set up a response system that utilizes the tutor instructions along with the context retrieved from the documents to provide detailed and educational answers.\n",
    "\n",
    "**Key Elements of the System:**\n",
    "\n",
    "- **`system_prompt`**: Structures the AI's response approach by incorporating tutor instructions and explicitly directing the use of retrieved document context to answer queries, ensuring responses are pedagogically aligned and informative.\n",
    "\n",
    "- **`qa_prompt`**: This template structures the interaction by embedding the system’s guidance, chat history, and user’s current query. It guides the AI in engaging with the student in a manner that is responsive and informed by prior interactions.\n",
    "\n",
    "- **`question_answer_chain`**: Executes the AI's strategy for responding, utilizing the prompt to direct document retrieval and conversation analysis to construct answers that are contextually aware and educationally relevant.\n",
    "\n",
    "By employing these elements, the AI tutor is equipped to provide responses that are not just reactive but also deeply integrated with the educational content and objectives of the Astronomy 12 course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48d9c802-4f8c-4812-b610-601d0dc51789",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = (\n",
    "    f\"{tutor_instructions.page_content}\\n\\n\"\n",
    "    \"## Your Task\\n\\n\"\n",
    "    \"Following the instructions above, use the following pieces of retrieved context to answer the question. \\n\\n\"\n",
    "    \"# Context\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "qa_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "])\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d659e6ca-25e2-4315-8e8d-5977c21ac6b3",
   "metadata": {},
   "source": [
    "### Implementing the Retrieval-Augmented Generation Chain\n",
    "\n",
    "To enhance the AI tutor's ability to deliver precise and contextually relevant answers, we integrate a retrieval-augmented generation (RAG) chain into the system. This structure utilizes both the power of document retrieval and the generative capabilities of language models.\n",
    "\n",
    "**Breakdown:**\n",
    "\n",
    "- **`create_retrieval_chain`**: This function links the `history_aware_retriever` with the `question_answer_chain`. The retriever first identifies relevant documents based on the user’s query and the context from previous interactions, while the question-answer chain generates responses based on the retrieved information. This combination ensures that the AI's responses are both informed by the course content and tailored to the ongoing conversation.\n",
    "\n",
    "- **`RunnableWithMessageHistory`**: Wraps the RAG chain to make it aware of the conversational history. This wrapper ensures continuity and context preservation across multiple interactions with the same student, simulating a more human-like tutoring experience. It uses three keys to manage the flow of information:\n",
    "  - `input_messages_key`: Specifies the key under which incoming student queries are stored.\n",
    "  - `history_messages_key`: Indicates where the chat history is maintained to provide context.\n",
    "  - `output_messages_key`: Defines the key for storing the AI’s responses, which can be referenced in future interactions.\n",
    "\n",
    "This setup enables the AI tutor to not just respond to isolated queries but to engage in a dynamic, ongoing educational dialogue. By leveraging both retrieval and generative processes, the tutor can provide answers that are deeply integrated with the educational content and are responsive to the evolving needs of the student, enhancing the learning experience in the Astronomy 12 course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "322f67f7-421b-4880-9402-5d75888172ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)\n",
    "conversational_rag_chain = RunnableWithMessageHistory(\n",
    "    rag_chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    "    output_messages_key=\"answer\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5805d639-8873-4963-b16f-cc57986c1124",
   "metadata": {},
   "source": [
    "## Testing the AI Tutor\n",
    "\n",
    "Finally, we'll test our AI tutor by simulating a few student inquiries to see how it performs in a real-world educational scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "750597ad-c44c-41ff-adb6-89432dcaeba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Great question! Before we dive into the calculation, do you know which formula is used to calculate the surface gravity of a planet?\n"
     ]
    }
   ],
   "source": [
    "response = conversational_rag_chain.invoke({\"input\": \"How do I calculate the surface gravity of a planet given its mass and radius?\"}, \n",
    "                                           config={\"configurable\": {\"session_id\": \"abc1234\"}})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6098e79f-25ce-4bf2-994c-4fc5f15b64ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're on the right track with the gravitational force equation! However, for surface gravity specifically, we use a slightly different approach. \n",
      "\n",
      "Surface gravity ($g$) can be derived from Newton's law of universal gravitation. Do you know how we can express surface gravity in terms of the mass and radius of the planet?\n"
     ]
    }
   ],
   "source": [
    "response = conversational_rag_chain.invoke({\"input\": \"Well I know that F=G*m1*m2/r^2\"}, \n",
    "                                           config={\"configurable\": {\"session_id\": \"abc1234\"}})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73f404d0-7000-4eb5-8d36-b43d68cd6577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, exactly! We can use Newton's second law, $F = ma$, along with the gravitational force formula you mentioned. \n",
      "\n",
      "To find the surface gravity, we consider the force acting on an object at the surface of a planet due to gravity. Can you think of how we can combine these ideas to derive the formula for surface gravity ($g$)?\n"
     ]
    }
   ],
   "source": [
    "response = conversational_rag_chain.invoke({\"input\": \"Do we need one of Newton's second law, F=ma?\"}, \n",
    "                                           config={\"configurable\": {\"session_id\": \"abc1234\"}})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb4e41d-8ec1-4239-868a-26eb5cabda0d",
   "metadata": {},
   "source": [
    "We can also use the most relevant course material found by the model to recommend further reading:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6986ac7e-12a8-4390-9bfa-835195719799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended course content for review:\n",
      "- [Lesson 2.2 gravity](https://teaghan.github.io/astronomy-12/md_files/2_2_gravity.html)\n",
      "- [Unit 2](https://teaghan.github.io/astronomy-12/md_files/Unit2_README.html)\n",
      "- [Unit 2 Assignment](https://teaghan.github.io/astronomy-12/Unit2/Unit2_Assignment.pdf)\n",
      "- [Lesson 2.1 keplers laws](https://teaghan.github.io/astronomy-12/md_files/2_1_keplers_laws.html)\n"
     ]
    }
   ],
   "source": [
    "def generate_links(context_list):\n",
    "    base_url = \"https://teaghan.github.io/astronomy-12/\"\n",
    "    links = []\n",
    "\n",
    "    for context in context_list:\n",
    "        title = context.metadata['title']\n",
    "        content = context.page_content\n",
    "\n",
    "        # Handle README files\n",
    "        if \"_README.md\" in title:\n",
    "            unit_number = re.search(r\"# Unit(\\d+)_README\\.md\", title).group(1)\n",
    "            links.append(f\"- [Unit {unit_number}]({base_url}md_files/Unit{unit_number}_README.html)\")\n",
    "\n",
    "        # Handle lesson files\n",
    "        elif \".md\" in title and \"_\" in title:\n",
    "            # Extract lesson title from content\n",
    "            lesson_title_match = re.search(r'# (.*?)\\n', content)\n",
    "            lesson_title = lesson_title_match.group(1) if lesson_title_match else \"Lesson\"\n",
    "\n",
    "            lesson_parts = re.search(r\"# (\\d+)_(\\d+)_(\\w+)\\.md\", title)\n",
    "            if lesson_parts:\n",
    "                unit, lesson, name = lesson_parts.groups()\n",
    "                name_formatted = name.replace('_', ' ')  # Assuming names are using underscores instead of spaces\n",
    "                link_text = f\"Lesson {unit}.{lesson} {name_formatted}\"\n",
    "                links.append(f\"- [{link_text}]({base_url}md_files/{unit}_{lesson}_{name}.html)\")\n",
    "\n",
    "        # Handle assignments\n",
    "        elif \"Assignment\" in title:\n",
    "            assignment_number = re.search(r\"# Unit (\\d+) Assignment\", title).group(1)\n",
    "            links.append(f\"- [Unit {assignment_number} Assignment]({base_url}Unit{assignment_number}/Unit{assignment_number}_Assignment.pdf)\")\n",
    "\n",
    "    return f\"\\n\".join(links)\n",
    "\n",
    "print('Recommended course content for review:\\n' + generate_links(response['context']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bc0763-797b-438f-be43-c862ff0fc8ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
